{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -qq install ultralytics","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\npath = kagglehub.dataset_download(\"jessicali9530/celeba-dataset\")\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.transforms.functional as TF\nimport torchvision.transforms as transforms\nimport numpy as np, torch, cv2, os, glob\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\nfrom tqdm import tqdm\nfrom PIL import Image\n\n# ───────────────────────────────── CONFIG ─────────────────────────────────\nINPUT_DIR  = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\nMODEL_PATH = \"/kaggle/input/yolo-world-small/pytorch/default/1/yolov8s-world.pt\"\nMASK_H, MASK_W = 128, 128\n\nPROMPTS = ['eye', 'mouth', 'ear', 'nose', 'nosetip', 'face', 'chin', 'head', 'eyebrows']\nWEIGHTS = {\n    'eye': 4.5, 'mouth': 4.0, 'nose': 4.0, 'nosetip': 3.0,\n    'chin': 4.0, 'ear': 4.0, 'eyebrows': 4.0, 'face': 4.0, 'head': 1.2\n}\n\n# ───────────────────────────────── UTILS ─────────────────────────────────\ndef inverse_gaussian_fade(shape):\n    hh, ww = shape\n    y, x = np.meshgrid(np.linspace(-1,1,ww), np.linspace(-1,1,hh))\n    distance = np.sqrt(x**2 + y**2)\n    sigma = 0.6\n    fade = 1 - np.exp(-(distance**2) / (2 * sigma**2))\n    return fade.astype(np.float32)\n\nINV_FADE_CACHE = {}\n\ndef get_inverse_fade(shape):\n    if shape not in INV_FADE_CACHE:\n        INV_FADE_CACHE[shape] = inverse_gaussian_fade(shape)\n    return INV_FADE_CACHE[shape]\n\ndef extract_edges(img_gray):\n    scharr_x = cv2.Scharr(img_gray, cv2.CV_32F, 1, 0)\n    scharr_y = cv2.Scharr(img_gray, cv2.CV_32F, 0, 1)\n    scharr = np.sqrt(scharr_x**2 + scharr_y**2)\n    scharr /= (scharr.max() + 1e-8)\n\n    canny = cv2.Canny(img_gray, 50, 150).astype(np.float32)/255.0\n\n    combined = (0.5 * scharr + 0.5 * canny)\n    return combined / (combined.max() + 1e-8)\n\ndef gaussian_fade(shape):\n    hh, ww = shape\n    y, x = np.meshgrid(np.linspace(-1,1,ww), np.linspace(-1,1,hh))\n    fade = np.exp(-2.0 * (x**2 + y**2))\n    return fade.astype(np.float32)\n\nFADE_CACHE = {}\n\ndef get_fade(shape):\n    if shape not in FADE_CACHE:\n        FADE_CACHE[shape] = gaussian_fade(shape)\n    return FADE_CACHE[shape]\n\ndef preprocess_exactly_like_dataset(img_path: str) -> np.ndarray:\n    pil_image = Image.open(img_path).convert('RGB')\n    \n    transform = transforms.Compose([\n        transforms.CenterCrop((178, 178)),\n        transforms.Resize((128, 128)),\n    ])\n    \n    processed_pil = transform(pil_image)\n    \n    img_rgb = np.array(processed_pil)\n    \n    return img_rgb\n\ndef detailed_heatmap_aligned(img_path, yolo_model, prompts, weights):\n    img128 = preprocess_exactly_like_dataset(img_path)\n    H, W = 128, 128\n    gray128 = cv2.cvtColor(img128, cv2.COLOR_RGB2GRAY)\n    \n    results = yolo_model(img128, conf=0.001, iou=0.1, verbose=False)[0]\n    \n    if len(results.boxes) == 0:\n        return np.zeros((H, W), dtype=np.float32)\n    \n    boxes = results.boxes.xyxy.cpu().numpy().astype(int)\n    classes = results.boxes.cls.cpu().numpy().astype(int)\n    confidences = results.boxes.conf.cpu().numpy()\n\n    combined_heatmap = np.zeros((H, W), dtype=np.float32)\n\n    for (x1, y1, x2, y2), cls, conf in zip(boxes, classes, confidences):\n        lab = prompts[cls]\n        weight = weights.get(lab, 1.0)\n\n        x1, y1 = max(0, x1), max(0, y1)\n        x2, y2 = min(W, x2), min(H, y2)\n        \n        if x2 <= x1 or y2 <= y1:\n            continue\n\n        crop = gray128[y1:y2, x1:x2]\n        if crop.size == 0:\n            continue\n\n        edges = extract_edges(crop)\n        \n        box_w, box_h = x2 - x1, y2 - y1\n        pad = max(8, min(box_w, box_h) // 4)\n        \n        y1_exp = max(0, y1 - pad)\n        y2_exp = min(H, y2 + pad)\n        x1_exp = max(0, x1 - pad)\n        x2_exp = min(W, x2 + pad)\n        \n        local_h, local_w = y2_exp - y1_exp, x2_exp - x1_exp\n        local_heatmap = np.zeros((local_h, local_w), dtype=np.float32)\n        \n        crop_start_y = y1 - y1_exp\n        crop_start_x = x1 - x1_exp\n        \n        edges_resized = cv2.resize(edges, (box_w, box_h), interpolation=cv2.INTER_LINEAR)\n        \n        if lab == 'head':\n            edges_resized *= get_fade(edges_resized.shape)\n            weight *= 0.5\n        elif lab == 'face':\n            fade = get_inverse_fade(edges_resized.shape)\n            fade = 0.3 + 0.7 * fade\n            edges_resized *= fade\n        else:\n            edges_resized *= get_fade(edges_resized.shape)\n        \n        local_heatmap[crop_start_y:crop_start_y + box_h, crop_start_x:crop_start_x + box_w] = edges_resized\n        \n        center_y, center_x = local_h // 2, local_w // 2\n        y_coords, x_coords = np.ogrid[:local_h, :local_w]\n        \n        distances = np.sqrt((x_coords - center_x)**2 + (y_coords - center_y)**2)\n        max_dist = min(local_h, local_w) / 2\n        \n        radial_fade = np.exp(-0.8 * (distances / max_dist)**2)\n        radial_fade = np.clip(radial_fade, 0.3, 1.0)\n        \n        local_heatmap *= radial_fade\n        \n        combined_heatmap[y1_exp:y2_exp, x1_exp:x2_exp] = np.maximum(\n            combined_heatmap[y1_exp:y2_exp, x1_exp:x2_exp], \n            local_heatmap * weight\n        )\n\n    combined_heatmap = cv2.GaussianBlur(combined_heatmap, (21, 21), sigmaX=2.0)\n    \n    if combined_heatmap.max() > combined_heatmap.min():\n        combined_heatmap = (combined_heatmap - combined_heatmap.min()) / (combined_heatmap.max() - combined_heatmap.min())\n    \n    return combined_heatmap\n\ndef verify_alignment_with_dataset(img_path, dataset_loader_func=None):\n    our_img = preprocess_exactly_like_dataset(img_path)\n    \n    if dataset_loader_func:\n        dataset_img = dataset_loader_func(img_path)\n        \n        diff = np.abs(our_img.astype(float) - dataset_img.astype(float))\n        max_diff = diff.max()\n        \n        print(f\"✅ Alignment check: max pixel difference = {max_diff}\")\n        if max_diff < 1e-6:\n            print(\"PERFECT ALIGNMENT!\")\n        elif max_diff < 1.0:\n            print(\"Very good alignment (sub-pixel differences)\")\n        else:\n            print(\"Significant differences detected\")\n    \n    return our_img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:13:51.103059Z","iopub.execute_input":"2025-10-21T13:13:51.103468Z","iopub.status.idle":"2025-10-21T13:13:51.125012Z","shell.execute_reply.started":"2025-10-21T13:13:51.103429Z","shell.execute_reply":"2025-10-21T13:13:51.124241Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ───────────────────────────────── SETUP ─────────────────────────────────\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nyolo_model = YOLO(MODEL_PATH).to(device)\nyolo_model.set_classes(PROMPTS)\nyolo_model.eval()\n\nimage_paths = sorted(glob.glob(os.path.join(INPUT_DIR, '*.jpg')))\nN = len(image_paths)\nassert N > 0, \"No images found\"\n\nIMG_SIZE = 128\nCHUNK = 10_000\n\nprint(f\"[info] images: {N} | chunk: {CHUNK} | device: {device}\")\n\nimport h5py\n\nwith h5py.File('heatmaps_200k_nocomp.h5', 'w') as hf:\n    heatmaps_ds = hf.create_dataset(\n        'heatmaps',\n        shape=(N, IMG_SIZE, IMG_SIZE),\n        dtype='f2',\n        compression=None,\n        chunks=(1, IMG_SIZE, IMG_SIZE)\n    )\n\n    write_start = 0\n    buf = []\n    buf_paths = []\n\n    print(\"Generating pixel-perfect aligned heatmaps (streaming to disk)...\")\n    for idx, path in enumerate(tqdm(image_paths, desc=\"Extracting aligned heatmaps\")):\n        _ = preprocess_exactly_like_dataset(path)\n        hm = detailed_heatmap_aligned(path, yolo_model, PROMPTS, WEIGHTS)\n\n        buf.append(hm.astype(np.float16))\n        buf_paths.append(idx)\n\n        if len(buf) == CHUNK:\n            write_end = write_start + len(buf)\n            heatmaps_ds[write_start:write_end, :, :] = np.stack(buf, axis=0)\n            hf.flush()\n            buf.clear()\n            buf_paths.clear()\n            write_start = write_end\n\n    if buf:\n        write_end = write_start + len(buf)\n        heatmaps_ds[write_start:write_end, :, :] = np.stack(buf, axis=0)\n        hf.flush()\n\nprint(f\"[done] Saved {N} PIXEL-PERFECT aligned heatmaps\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}